## Spark SQL、DataFrame 和 Dataset 指南

Spark SQL 是一个用于结构化数据处理的 Spark 模块。与基本的 Spark RDD API 不同，Spark SQL 提供的接口为 Spark 提供了有关数据结构和执行计算的更多信息。在内部，Spark SQL 使用这些额外信息来执行额外的优化。有几种方法可以与 Spark SQL 交互，包括 SQL 和 Dataset API。在计算结果时，使用相同的执行引擎，无论您使用哪种 API/语言来表达计算。这种统一意味着开发人员可以轻松地在不同的 API 之间来回切换，具体取决于哪种 API 提供最自然的方式来表达给定的转换。

本页上的所有示例都使用 Spark 分发版中包含的示例数据，可以在 `spark-shell`、`pyspark` shell 或 `sparkR` shell 中运行。

## SQL

Spark SQL 的一个用途是执行 SQL 查询。Spark SQL 也可以用于从现有的 Hive 安装中读取数据。有关如何配置此功能的更多信息，请参阅 [Hive 表](https://spark.apache.ac.cn/docs/latest/sql-data-sources-hive-tables.html) 部分。当从另一种编程语言中运行 SQL 时，结果将作为 [Dataset/DataFrame](#datasets-and-dataframes) 返回。您还可以使用 [命令行](https://spark.apache.ac.cn/docs/latest/sql-distributed-sql-engine.html#running-the-spark-sql-cli) 或通过 [JDBC/ODBC](https://spark.apache.ac.cn/docs/latest/sql-distributed-sql-engine.html#running-the-thrift-jdbcodbc-server) 与 SQL 接口交互。

## Dataset 和 DataFrame

Dataset 是一个分布式数据集合。Dataset 是 Spark 1.6 中添加的一个新接口，它提供了 RDD 的优势（强类型、能够使用强大的 lambda 函数）以及 Spark SQL 优化执行引擎的优势。Dataset 可以从 JVM 对象 [构建](https://spark.apache.ac.cn/docs/latest/sql-getting-started.html#creating-datasets)，然后使用函数式转换 (`map`、`flatMap`、`filter` 等) 进行操作。Dataset API 在 [Scala](https://spark.apache.ac.cn/docs/latest/api/scala/org/apache/spark/sql/Dataset.html) 和 [Java](https://spark.apache.ac.cn/docs/latest/api/java/index.html?org/apache/spark/sql/Dataset.html) 中可用。Python 不支持 Dataset API。但由于 Python 的动态特性，Dataset API 的许多优势已经可用（例如，您可以通过名称自然地访问行的字段 `row.columnName`）。R 的情况类似。

DataFrame 是一个组织成命名列的 *Dataset*。它在概念上等效于关系数据库中的表或 R/Python 中的 DataFrame，但具有更丰富的内部优化。DataFrame 可以从各种 [来源](https://spark.apache.ac.cn/docs/latest/sql-data-sources.html) 构建，例如：结构化数据文件、Hive 中的表、外部数据库或现有的 RDD。DataFrame API 在 Scala、Java、[Python](https://spark.apache.ac.cn/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.html#pyspark.sql.DataFrame) 和 [R](https://spark.apache.ac.cn/docs/latest/api/R/index.html) 中可用。在 Scala 和 Java 中，DataFrame 由 `Row` 的 Dataset 表示。在 [Scala API](https://spark.apache.ac.cn/docs/latest/api/scala/org/apache/spark/sql/Dataset.html) 中，`DataFrame` 只是 `Dataset[Row]` 的类型别名。而在 [Java API](https://spark.apache.ac.cn/docs/latest/api/java/index.html?org/apache/spark/sql/Dataset.html) 中，用户需要使用 `Dataset<Row>` 来表示 `DataFrame`。

在本文件中，我们将经常将 Scala/Java 的 `Row` 的 Dataset 称为 DataFrame。